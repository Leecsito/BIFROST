{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","# ğŸ¦ PROYECTO: EXPANSIÃ“N Y LIMPIEZA DE DATASET BANCARIO\n","# Autor: Tu nombre\n","# Objetivo: Expandir dataset de 5,300 â†’ 50,000 filas, ensuciar y subir a Firebase\n","# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# PASO 1: INSTALACIÃ“N E IMPORTACIÃ“N DE LIBRERÃAS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","!pip install kagglehub -q\n","\n","import kagglehub\n","import pandas as pd\n","import numpy as np\n","import uuid\n","import requests\n","import json\n","import os\n","from datetime import datetime, timedelta\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"âœ… LibrerÃ­as cargadas correctamente\\n\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# PASO 2: DESCARGA Y CARGA DEL DATASET ORIGINAL\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"ğŸ“¥ Descargando dataset de Kaggle...\")\n","try:\n","    path = kagglehub.dataset_download(\"pradeepkumar2424/usa-banking-transactions-dataset-2023-2024\")\n","    print(f\"âœ… Dataset descargado en: {path}\")\n","\n","    # Buscar archivo CSV\n","    archivos = os.listdir(path)\n","    csv_files = [f for f in archivos if f.endswith('.csv')]\n","\n","    if not csv_files:\n","        raise FileNotFoundError(\"âŒ No se encontrÃ³ ningÃºn archivo CSV\")\n","\n","    # Cargar el DataFrame\n","    full_path = os.path.join(path, csv_files[0])\n","    df_inicio = pd.read_csv(full_path)\n","\n","    print(f\"âœ… Archivo cargado: {csv_files[0]}\")\n","    print(f\"ğŸ“Š Dimensiones originales: {df_inicio.shape}\")\n","    print(f\"ğŸ“‹ Columnas: {list(df_inicio.columns)}\\n\")\n","\n","except Exception as e:\n","    print(f\"âŒ Error al cargar dataset: {e}\")\n","    raise\n","\n","# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# PASO 3: EXPANSIÃ“N DEL DATASET (5,300 â†’ 50,000 FILAS)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"ğŸ”„ Expandiendo dataset a 50,000 filas...\")\n","\n","OBJETIVO_FILAS = 50000\n","filas_actuales = len(df_inicio)\n","filas_a_crear = OBJETIVO_FILAS - filas_actuales\n","\n","print(f\"   â€¢ Filas actuales: {filas_actuales:,}\")\n","print(f\"   â€¢ Filas a generar: {filas_a_crear:,}\")\n","\n","# Muestreo con reemplazo\n","df_nuevos = df_inicio.sample(n=filas_a_crear, replace=True).copy()\n","\n","# Generar fechas aleatorias entre 2020-2022\n","def random_dates(start_year, end_year, n):\n","    start = datetime(start_year, 1, 1)\n","    end = datetime(end_year, 12, 31, 23, 59, 59)\n","    delta = end - start\n","    int_deltas = np.random.randint(0, int(delta.total_seconds()), n)\n","    return [start + timedelta(seconds=int(i)) for i in int_deltas]\n","\n","fechas_generadas = random_dates(2020, 2022, filas_a_crear)\n","df_nuevos['Transaction_Date'] = fechas_generadas\n","\n","# CORRECCIÃ“N: Regenerar IDs Ãºnicos GARANTIZADOS\n","print(\"   â€¢ Generando IDs Ãºnicos...\")\n","ids_existentes = set(df_inicio['Transaction_ID'].astype(str))\n","nuevos_ids = []\n","\n","for _ in range(filas_a_crear):\n","    nuevo_id = str(uuid.uuid4())\n","    while nuevo_id in ids_existentes:  # Evita colisiones (extremadamente raro pero posible)\n","        nuevo_id = str(uuid.uuid4())\n","    nuevos_ids.append(nuevo_id)\n","    ids_existentes.add(nuevo_id)\n","\n","df_nuevos['Transaction_ID'] = nuevos_ids\n","\n","# TambiÃ©n regenerar Account_Numbers con variaciÃ³n\n","if 'Account_Number' in df_nuevos.columns:\n","    account_base = df_nuevos['Account_Number'].astype(str)\n","    df_nuevos['Account_Number'] = account_base.apply(\n","        lambda x: str(int(x) + np.random.randint(-1000, 1000)) if x.isdigit() else x\n","    )\n","\n","# Unir datasets\n","df_completo = pd.concat([df_inicio, df_nuevos], ignore_index=True)\n","df_completo['Transaction_Date'] = pd.to_datetime(df_completo['Transaction_Date'])\n","\n","print(f\"âœ… Dataset expandido: {df_completo.shape}\")\n","print(f\"   â€¢ Rango de fechas: {df_completo['Transaction_Date'].min().date()} a {df_completo['Transaction_Date'].max().date()}\")\n","print(f\"   â€¢ IDs Ãºnicos verificados: {df_completo['Transaction_ID'].nunique() == len(df_completo)}\\n\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# PASO 4: ENSUCIAMIENTO INTELIGENTE DEL DATASET (KDD)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"ğŸ§¹ Ensuciando datos para proceso KDD...\")\n","\n","df = df_completo.copy()\n","\n","# 4.1 - VALORES NULOS (5% en columnas realistas)\n","print(\"   â€¢ Insertando valores nulos (5%)...\")\n","columnas_nulos = ['Customer_Occupation', 'Transaction_Description', 'City']\n","for col in columnas_nulos:\n","    if col in df.columns:\n","        mask_nulos = np.random.rand(len(df)) < 0.05\n","        df.loc[mask_nulos, col] = np.nan\n","\n","nulos_totales = df.isnull().sum().sum()\n","print(f\"     â†’ {nulos_totales:,} valores nulos insertados\")\n","\n","# 4.2 - INCONSISTENCIAS DE TEXTO (7%)\n","print(\"   â€¢ Insertando inconsistencias de texto (7%)...\")\n","if 'City' in df.columns:\n","    indices_ciudad = df.sample(frac=0.07).index\n","    df.loc[indices_ciudad, 'City'] = df.loc[indices_ciudad, 'City'].str.lower()\n","\n","if 'Payment_Method' in df.columns:\n","    indices_pago = df.sample(frac=0.07).index\n","    df.loc[indices_pago, 'Payment_Method'] = df.loc[indices_pago, 'Payment_Method'] + \"  \"\n","\n","inconsistencias = len(indices_ciudad) + len(indices_pago)\n","print(f\"     â†’ {inconsistencias:,} inconsistencias insertadas\")\n","\n","# 4.3 - OUTLIERS EN MONTOS (25 transacciones extremas)\n","print(\"   â€¢ Insertando outliers en montos (25)...\")\n","if 'Transaction_Amount' in df.columns:\n","    indices_outliers = df.sample(n=25).index\n","    df.loc[indices_outliers, 'Transaction_Amount'] = df.loc[indices_outliers, 'Transaction_Amount'] * np.random.uniform(50, 150, 25)\n","    print(f\"     â†’ 25 outliers insertados\")\n","\n","# 4.4 - DUPLICADOS (100 filas con IDs NUEVOS pero contenido duplicado)\n","print(\"   â€¢ Insertando duplicados (100)...\")\n","filas_duplicadas = df.sample(n=100).copy()\n","\n","# IMPORTANTE: Generar nuevos IDs para los duplicados (para evitar error de Ã­ndice Ãºnico)\n","nuevos_ids_duplicados = []\n","for _ in range(100):\n","    nuevo_id = str(uuid.uuid4())\n","    while nuevo_id in ids_existentes:\n","        nuevo_id = str(uuid.uuid4())\n","    nuevos_ids_duplicados.append(nuevo_id)\n","    ids_existentes.add(nuevo_id)\n","\n","filas_duplicadas['Transaction_ID'] = nuevos_ids_duplicados\n","\n","df = pd.concat([df, filas_duplicadas], ignore_index=True)\n","\n","# Ahora verificamos duplicados SIN considerar Transaction_ID\n","columnas_sin_id = [col for col in df.columns if col != 'Transaction_ID']\n","duplicados_contenido = df.duplicated(subset=columnas_sin_id, keep=False).sum()\n","print(f\"     â†’ {duplicados_contenido:,} filas con contenido duplicado\")\n","\n","# Mezclar dataset\n","df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","print(f\"\\nâœ… Dataset ensuciado completamente\")\n","print(f\"   ğŸ“Š Dimensiones finales: {df.shape}\")\n","print(f\"   ğŸ” Resumen de suciedad:\")\n","print(f\"      - Valores nulos: {df.isnull().sum().sum():,}\")\n","print(f\"      - Duplicados (contenido): {duplicados_contenido:,}\")\n","print(f\"      - Outliers: 25 transacciones\")\n","print(f\"      - IDs Ãºnicos: {df['Transaction_ID'].nunique() == len(df)} âœ…\\n\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# PASO 5: PREPARACIÃ“N PARA FIREBASE\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"ğŸ”§ Preparando datos para Firebase...\")\n","\n","# Convertir fechas a string\n","df_subida = df.copy()\n","df_subida['Transaction_Date'] = df_subida['Transaction_Date'].astype(str)\n","\n","# Rellenar NaN para evitar errores en JSON\n","df_subida = df_subida.fillna(\"N/A\")\n","\n","# VERIFICACIÃ“N FINAL: Asegurar que todos los IDs son Ãºnicos\n","if df_subida['Transaction_ID'].duplicated().any():\n","    print(\"âš ï¸  ADVERTENCIA: Se encontraron IDs duplicados, regenerando...\")\n","    duplicados_mask = df_subida['Transaction_ID'].duplicated(keep='first')\n","    num_duplicados = duplicados_mask.sum()\n","\n","    for idx in df_subida[duplicados_mask].index:\n","        nuevo_id = str(uuid.uuid4())\n","        while nuevo_id in df_subida['Transaction_ID'].values:\n","            nuevo_id = str(uuid.uuid4())\n","        df_subida.at[idx, 'Transaction_ID'] = nuevo_id\n","\n","    print(f\"âœ… {num_duplicados} IDs regenerados correctamente\")\n","\n","# Convertir a diccionario usando Transaction_ID como clave\n","data_firebase = df_subida.set_index('Transaction_ID').to_dict(orient='index')\n","\n","print(f\"âœ… {len(data_firebase):,} registros preparados para subida\")\n","print(f\"   â€¢ VerificaciÃ³n final: {len(data_firebase) == len(df_subida)} âœ…\\n\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# PASO 6: SUBIDA A FIREBASE (EN LOTES OPTIMIZADOS)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"â˜ï¸  Subiendo a Firebase Realtime Database...\")\n","\n","BASE_URL = \"https://bifrost-e5592-default-rtdb.firebaseio.com/\"\n","NODO = \"transacciones_bancarias\"\n","TAMAÃ‘O_LOTE = 1000  # Firebase maneja bien lotes de ~1000 registros\n","\n","def subir_lote(nodo, datos_lote, lote_num):\n","    \"\"\"Sube un lote de datos a Firebase\"\"\"\n","    url = f\"{BASE_URL}{nodo}.json\"\n","    try:\n","        response = requests.patch(url, data=json.dumps(datos_lote), timeout=30)\n","        if response.status_code == 200:\n","            return True, None\n","        else:\n","            return False, response.text\n","    except Exception as e:\n","        return False, str(e)\n","\n","# Dividir en lotes\n","transaction_ids = list(data_firebase.keys())\n","total_lotes = (len(transaction_ids) + TAMAÃ‘O_LOTE - 1) // TAMAÃ‘O_LOTE\n","\n","print(f\"   â€¢ Total de lotes: {total_lotes}\")\n","print(f\"   â€¢ TamaÃ±o por lote: ~{TAMAÃ‘O_LOTE} registros\\n\")\n","\n","exitosos = 0\n","fallidos = 0\n","\n","for i in tqdm(range(total_lotes), desc=\"Subiendo lotes\"):\n","    inicio = i * TAMAÃ‘O_LOTE\n","    fin = min((i + 1) * TAMAÃ‘O_LOTE, len(transaction_ids))\n","\n","    ids_lote = transaction_ids[inicio:fin]\n","    datos_lote = {id_: data_firebase[id_] for id_ in ids_lote}\n","\n","    exito, error = subir_lote(NODO, datos_lote, i+1)\n","\n","    if exito:\n","        exitosos += len(datos_lote)\n","    else:\n","        fallidos += len(datos_lote)\n","        print(f\"\\nâš ï¸  Error en lote {i+1}: {error}\")\n","\n","print(f\"\\n{'='*60}\")\n","print(f\"âœ… SUBIDA COMPLETADA\")\n","print(f\"{'='*60}\")\n","print(f\"   â€¢ Registros exitosos: {exitosos:,}\")\n","print(f\"   â€¢ Registros fallidos: {fallidos:,}\")\n","print(f\"   â€¢ URL Firebase: {BASE_URL}{NODO}\")\n","print(f\"\\nğŸ‰ Â¡Proceso terminado! Tu dataset estÃ¡ listo para anÃ¡lisis KDD.\\n\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# BONUS: VERIFICACIÃ“N RÃPIDA\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"ğŸ” VerificaciÃ³n rÃ¡pida de datos subidos...\")\n","try:\n","    response = requests.get(f\"{BASE_URL}{NODO}.json?shallow=true&limitToFirst=1\")\n","    if response.status_code == 200:\n","        data = response.json()\n","        if data:\n","            print(f\"âœ… Firebase respondiendo correctamente\")\n","            print(f\"   â€¢ Primer ID en base: {list(data.keys())[0]}\")\n","        else:\n","            print(\"âš ï¸  Advertencia: Firebase vacÃ­o (puede tardar unos segundos en sincronizar)\")\n","except Exception as e:\n","    print(f\"âš ï¸  No se pudo verificar: {e}\")\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"ğŸ“ NOTAS FINALES:\")\n","print(\"=\"*60)\n","print(\"1. Dataset expandido de 5,389 â†’ 50,100 filas\")\n","print(\"2. Datos ensuciados listos para limpieza KDD\")\n","print(\"3. Subido a Firebase en un Ãºnico nodo: 'transacciones_bancarias'\")\n","print(\"4. Para limpiar, busca: nulos, duplicados, outliers, inconsistencias\")\n","print(\"5. Todos los Transaction_IDs son Ãºnicos (sin colisiones)\")\n","print(\"\\nÂ¡Buena suerte con tu proyecto! ğŸš€\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dag6Pbais4Gh","executionInfo":{"status":"ok","timestamp":1769738316223,"user_tz":300,"elapsed":41432,"user":{"displayName":"Johan Caizaguano","userId":"03823090711317079059"}},"outputId":"f1a19f9f-f8ea-43a4-ae51-42355a5750b4","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… LibrerÃ­as cargadas correctamente\n","\n","ğŸ“¥ Descargando dataset de Kaggle...\n","Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n","Downloading from https://www.kaggle.com/api/v1/datasets/download/pradeepkumar2424/usa-banking-transactions-dataset-2023-2024?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 580k/580k [00:00<00:00, 64.0MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n","âœ… Dataset descargado en: /root/.cache/kagglehub/datasets/pradeepkumar2424/usa-banking-transactions-dataset-2023-2024/versions/1\n","âœ… Archivo cargado: Banking_Transactions_USA_2023_2024.csv\n","ğŸ“Š Dimensiones originales: (5389, 20)\n","ğŸ“‹ Columnas: ['Transaction_ID', 'Account_Number', 'Transaction_Date', 'Transaction_Amount', 'Merchant_Name', 'Transaction_Type', 'Category', 'City', 'Country', 'Payment_Method', 'Customer_Age', 'Customer_Gender', 'Customer_Occupation', 'Customer_Income', 'Account_Balance', 'Transaction_Status', 'Fraud_Flag', 'Discount_Applied', 'Loyalty_Points_Earned', 'Transaction_Description']\n","\n","ğŸ”„ Expandiendo dataset a 50,000 filas...\n","   â€¢ Filas actuales: 5,389\n","   â€¢ Filas a generar: 44,611\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["   â€¢ Generando IDs Ãºnicos...\n","âœ… Dataset expandido: (50000, 20)\n","   â€¢ Rango de fechas: 2020-01-01 a 2025-01-20\n","   â€¢ IDs Ãºnicos verificados: True\n","\n","ğŸ§¹ Ensuciando datos para proceso KDD...\n","   â€¢ Insertando valores nulos (5%)...\n","     â†’ 7,443 valores nulos insertados\n","   â€¢ Insertando inconsistencias de texto (7%)...\n","     â†’ 7,000 inconsistencias insertadas\n","   â€¢ Insertando outliers en montos (25)...\n","     â†’ 25 outliers insertados\n","   â€¢ Insertando duplicados (100)...\n","     â†’ 200 filas con contenido duplicado\n","\n","âœ… Dataset ensuciado completamente\n","   ğŸ“Š Dimensiones finales: (50100, 20)\n","   ğŸ” Resumen de suciedad:\n","      - Valores nulos: 7,464\n","      - Duplicados (contenido): 200\n","      - Outliers: 25 transacciones\n","      - IDs Ãºnicos: True âœ…\n","\n","ğŸ”§ Preparando datos para Firebase...\n","âœ… 50,100 registros preparados para subida\n","   â€¢ VerificaciÃ³n final: True âœ…\n","\n","â˜ï¸  Subiendo a Firebase Realtime Database...\n","   â€¢ Total de lotes: 51\n","   â€¢ TamaÃ±o por lote: ~1000 registros\n","\n"]},{"output_type":"stream","name":"stderr","text":["Subiendo lotes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:26<00:00,  1.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","âœ… SUBIDA COMPLETADA\n","============================================================\n","   â€¢ Registros exitosos: 50,100\n","   â€¢ Registros fallidos: 0\n","   â€¢ URL Firebase: https://bifrost-e5592-default-rtdb.firebaseio.com/transacciones_bancarias\n","\n","ğŸ‰ Â¡Proceso terminado! Tu dataset estÃ¡ listo para anÃ¡lisis KDD.\n","\n","ğŸ” VerificaciÃ³n rÃ¡pida de datos subidos...\n","âœ… Firebase respondiendo correctamente\n","   â€¢ Primer ID en base: 000030fb-cbf0-42ab-8719-0c7862e73f7f\n","\n","============================================================\n","ğŸ“ NOTAS FINALES:\n","============================================================\n","1. Dataset expandido de 5,389 â†’ 50,100 filas\n","2. Datos ensuciados listos para limpieza KDD\n","3. Subido a Firebase en un Ãºnico nodo: 'transacciones_bancarias'\n","4. Para limpiar, busca: nulos, duplicados, outliers, inconsistencias\n","5. Todos los Transaction_IDs son Ãºnicos (sin colisiones)\n","\n","Â¡Buena suerte con tu proyecto! ğŸš€\n"]}]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":634},"id":"ko_gc31Il2nV","executionInfo":{"status":"ok","timestamp":1769738316690,"user_tz":300,"elapsed":455,"user":{"displayName":"Johan Caizaguano","userId":"03823090711317079059"}},"outputId":"61ab7247-f529-48f3-da45-e52de9a44232","collapsed":true},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             Transaction_ID      Account_Number  \\\n","0      65cdd7b5-80cb-44e2-badd-8bdffeb1f48e  RPZD55039303803543   \n","1      cc2b2f49-c6d5-4a90-9296-ae08a2dcb574  VHWV64903657168897   \n","2      368af1a6-70f1-457d-ab1b-d6fd46ce10ad  LVBO11383514635476   \n","3      df391d94-a2de-43e5-be99-6e239e2a577e  BRUY69227025254110   \n","4      dbd7dd5d-3457-4fee-887d-7e427c5fb9ef  IOZZ48485694451421   \n","...                                     ...                 ...   \n","50095  bec5b162-994c-44b0-b9f9-bdf8f3a6f1bf  WQBP66487841383127   \n","50096  f67ed246-16d4-4a0a-bfae-78cf1fc2922e  BLST44617353606844   \n","50097  e4cf868d-2993-4d06-ab14-7a63c26c7ab5  XYTA78611407670347   \n","50098  98cf1188-06d2-4913-a117-3719b023a0ea  GDED46394762542926   \n","50099  ab3afc94-68fa-4ff3-908f-c3c3d3adde2c  ZOSQ21433952753674   \n","\n","         Transaction_Date  Transaction_Amount                Merchant_Name  \\\n","0     2022-01-24 18:26:07             3339.00   Rodriguez, Perez and Davis   \n","1     2024-03-03 09:18:37             1152.92                    Gomez PLC   \n","2     2021-12-28 19:29:34             1832.09    Ramos, Lopez and Robinson   \n","3     2022-05-14 14:44:09             1163.12     Lee, Jackson and Jackson   \n","4     2022-12-16 03:13:31             3661.27   Williams, Fry and Chandler   \n","...                   ...                 ...                          ...   \n","50095 2021-02-24 23:10:43              374.46  Graham, Bolton and Jennings   \n","50096 2021-08-22 05:41:28             3472.49               Phillips Group   \n","50097 2021-06-15 02:39:03             2061.62                   Phelps PLC   \n","50098 2023-02-02 05:03:38             4363.53                    Lopez PLC   \n","50099 2021-02-14 13:08:50             4307.44               Spencer-Pruitt   \n","\n","      Transaction_Type     Category         City Country   Payment_Method  \\\n","0                Debit         Food  Los Angeles     USA  Online Transfer   \n","1                Debit  Electronics      Chicago     USA      Credit Card   \n","2               Credit      Housing  Los Angeles     USA             Cash   \n","3                Debit    Utilities      Chicago     USA             Cash   \n","4                Debit      Savings     San Jose     USA       Debit Card   \n","...                ...          ...          ...     ...              ...   \n","50095           Credit      Savings      Houston     USA             Cash   \n","50096           Credit      Fitness          NaN     USA             Cash   \n","50097            Debit      Housing      Phoenix     USA  Online Transfer   \n","50098           Credit      Savings      Houston     USA       Debit Card   \n","50099            Debit      Grocery     San Jose     USA      Credit Card   \n","\n","       Customer_Age Customer_Gender              Customer_Occupation  \\\n","0                36          Others                   Cytogeneticist   \n","1                64          Others   Manufacturing systems engineer   \n","2                68          Female      Passenger transport manager   \n","3                47          Female         Environmental consultant   \n","4                39          Female               Investment analyst   \n","...             ...             ...                              ...   \n","50095            48          Female          Forest/woodland manager   \n","50096            58          Others            IT sales professional   \n","50097            48            Male                    Lexicographer   \n","50098            55          Female                         Lobbyist   \n","50099            35          Others  Geophysicist/field seismologist   \n","\n","       Customer_Income  Account_Balance Transaction_Status Fraud_Flag  \\\n","0             25423.57          8402.20             Failed        Yes   \n","1             61259.56          9965.04            Success         No   \n","2            102988.65         18545.48            Pending        Yes   \n","3             46604.80          3250.94            Success         No   \n","4             28624.64           465.89            Success         No   \n","...                ...              ...                ...        ...   \n","50095         23389.02          3975.51            Success         No   \n","50096        118343.82          8917.96            Success        Yes   \n","50097         96914.21          1042.69            Pending         No   \n","50098         60156.97          4953.27            Success        Yes   \n","50099         76870.23         19545.84            Pending         No   \n","\n","       Discount_Applied  Loyalty_Points_Earned  \\\n","0                 False                     54   \n","1                  True                    425   \n","2                 False                    425   \n","3                 False                    447   \n","4                  True                    367   \n","...                 ...                    ...   \n","50095             False                     67   \n","50096              True                    353   \n","50097              True                    117   \n","50098             False                    427   \n","50099             False                    445   \n","\n","                                 Transaction_Description  \n","0         Soldier town control serve however adult near.  \n","1      Six bed simple prove compare against scientist...  \n","2                                   Live I by help wish.  \n","3                        Attention worker short tonight.  \n","4                               Upon must black college.  \n","...                                                  ...  \n","50095             Answer act imagine everyone time none.  \n","50096        Fast traditional risk white she we reality.  \n","50097                         Same himself worker human.  \n","50098                  Community war actually prove get.  \n","50099                      Bar should without want else.  \n","\n","[50100 rows x 20 columns]"],"text/html":["\n","  <div id=\"df-07cfb1d2-e3d0-4a81-bd39-105839c15d65\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Transaction_ID</th>\n","      <th>Account_Number</th>\n","      <th>Transaction_Date</th>\n","      <th>Transaction_Amount</th>\n","      <th>Merchant_Name</th>\n","      <th>Transaction_Type</th>\n","      <th>Category</th>\n","      <th>City</th>\n","      <th>Country</th>\n","      <th>Payment_Method</th>\n","      <th>Customer_Age</th>\n","      <th>Customer_Gender</th>\n","      <th>Customer_Occupation</th>\n","      <th>Customer_Income</th>\n","      <th>Account_Balance</th>\n","      <th>Transaction_Status</th>\n","      <th>Fraud_Flag</th>\n","      <th>Discount_Applied</th>\n","      <th>Loyalty_Points_Earned</th>\n","      <th>Transaction_Description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>65cdd7b5-80cb-44e2-badd-8bdffeb1f48e</td>\n","      <td>RPZD55039303803543</td>\n","      <td>2022-01-24 18:26:07</td>\n","      <td>3339.00</td>\n","      <td>Rodriguez, Perez and Davis</td>\n","      <td>Debit</td>\n","      <td>Food</td>\n","      <td>Los Angeles</td>\n","      <td>USA</td>\n","      <td>Online Transfer</td>\n","      <td>36</td>\n","      <td>Others</td>\n","      <td>Cytogeneticist</td>\n","      <td>25423.57</td>\n","      <td>8402.20</td>\n","      <td>Failed</td>\n","      <td>Yes</td>\n","      <td>False</td>\n","      <td>54</td>\n","      <td>Soldier town control serve however adult near.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cc2b2f49-c6d5-4a90-9296-ae08a2dcb574</td>\n","      <td>VHWV64903657168897</td>\n","      <td>2024-03-03 09:18:37</td>\n","      <td>1152.92</td>\n","      <td>Gomez PLC</td>\n","      <td>Debit</td>\n","      <td>Electronics</td>\n","      <td>Chicago</td>\n","      <td>USA</td>\n","      <td>Credit Card</td>\n","      <td>64</td>\n","      <td>Others</td>\n","      <td>Manufacturing systems engineer</td>\n","      <td>61259.56</td>\n","      <td>9965.04</td>\n","      <td>Success</td>\n","      <td>No</td>\n","      <td>True</td>\n","      <td>425</td>\n","      <td>Six bed simple prove compare against scientist...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>368af1a6-70f1-457d-ab1b-d6fd46ce10ad</td>\n","      <td>LVBO11383514635476</td>\n","      <td>2021-12-28 19:29:34</td>\n","      <td>1832.09</td>\n","      <td>Ramos, Lopez and Robinson</td>\n","      <td>Credit</td>\n","      <td>Housing</td>\n","      <td>Los Angeles</td>\n","      <td>USA</td>\n","      <td>Cash</td>\n","      <td>68</td>\n","      <td>Female</td>\n","      <td>Passenger transport manager</td>\n","      <td>102988.65</td>\n","      <td>18545.48</td>\n","      <td>Pending</td>\n","      <td>Yes</td>\n","      <td>False</td>\n","      <td>425</td>\n","      <td>Live I by help wish.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>df391d94-a2de-43e5-be99-6e239e2a577e</td>\n","      <td>BRUY69227025254110</td>\n","      <td>2022-05-14 14:44:09</td>\n","      <td>1163.12</td>\n","      <td>Lee, Jackson and Jackson</td>\n","      <td>Debit</td>\n","      <td>Utilities</td>\n","      <td>Chicago</td>\n","      <td>USA</td>\n","      <td>Cash</td>\n","      <td>47</td>\n","      <td>Female</td>\n","      <td>Environmental consultant</td>\n","      <td>46604.80</td>\n","      <td>3250.94</td>\n","      <td>Success</td>\n","      <td>No</td>\n","      <td>False</td>\n","      <td>447</td>\n","      <td>Attention worker short tonight.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>dbd7dd5d-3457-4fee-887d-7e427c5fb9ef</td>\n","      <td>IOZZ48485694451421</td>\n","      <td>2022-12-16 03:13:31</td>\n","      <td>3661.27</td>\n","      <td>Williams, Fry and Chandler</td>\n","      <td>Debit</td>\n","      <td>Savings</td>\n","      <td>San Jose</td>\n","      <td>USA</td>\n","      <td>Debit Card</td>\n","      <td>39</td>\n","      <td>Female</td>\n","      <td>Investment analyst</td>\n","      <td>28624.64</td>\n","      <td>465.89</td>\n","      <td>Success</td>\n","      <td>No</td>\n","      <td>True</td>\n","      <td>367</td>\n","      <td>Upon must black college.</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>50095</th>\n","      <td>bec5b162-994c-44b0-b9f9-bdf8f3a6f1bf</td>\n","      <td>WQBP66487841383127</td>\n","      <td>2021-02-24 23:10:43</td>\n","      <td>374.46</td>\n","      <td>Graham, Bolton and Jennings</td>\n","      <td>Credit</td>\n","      <td>Savings</td>\n","      <td>Houston</td>\n","      <td>USA</td>\n","      <td>Cash</td>\n","      <td>48</td>\n","      <td>Female</td>\n","      <td>Forest/woodland manager</td>\n","      <td>23389.02</td>\n","      <td>3975.51</td>\n","      <td>Success</td>\n","      <td>No</td>\n","      <td>False</td>\n","      <td>67</td>\n","      <td>Answer act imagine everyone time none.</td>\n","    </tr>\n","    <tr>\n","      <th>50096</th>\n","      <td>f67ed246-16d4-4a0a-bfae-78cf1fc2922e</td>\n","      <td>BLST44617353606844</td>\n","      <td>2021-08-22 05:41:28</td>\n","      <td>3472.49</td>\n","      <td>Phillips Group</td>\n","      <td>Credit</td>\n","      <td>Fitness</td>\n","      <td>NaN</td>\n","      <td>USA</td>\n","      <td>Cash</td>\n","      <td>58</td>\n","      <td>Others</td>\n","      <td>IT sales professional</td>\n","      <td>118343.82</td>\n","      <td>8917.96</td>\n","      <td>Success</td>\n","      <td>Yes</td>\n","      <td>True</td>\n","      <td>353</td>\n","      <td>Fast traditional risk white she we reality.</td>\n","    </tr>\n","    <tr>\n","      <th>50097</th>\n","      <td>e4cf868d-2993-4d06-ab14-7a63c26c7ab5</td>\n","      <td>XYTA78611407670347</td>\n","      <td>2021-06-15 02:39:03</td>\n","      <td>2061.62</td>\n","      <td>Phelps PLC</td>\n","      <td>Debit</td>\n","      <td>Housing</td>\n","      <td>Phoenix</td>\n","      <td>USA</td>\n","      <td>Online Transfer</td>\n","      <td>48</td>\n","      <td>Male</td>\n","      <td>Lexicographer</td>\n","      <td>96914.21</td>\n","      <td>1042.69</td>\n","      <td>Pending</td>\n","      <td>No</td>\n","      <td>True</td>\n","      <td>117</td>\n","      <td>Same himself worker human.</td>\n","    </tr>\n","    <tr>\n","      <th>50098</th>\n","      <td>98cf1188-06d2-4913-a117-3719b023a0ea</td>\n","      <td>GDED46394762542926</td>\n","      <td>2023-02-02 05:03:38</td>\n","      <td>4363.53</td>\n","      <td>Lopez PLC</td>\n","      <td>Credit</td>\n","      <td>Savings</td>\n","      <td>Houston</td>\n","      <td>USA</td>\n","      <td>Debit Card</td>\n","      <td>55</td>\n","      <td>Female</td>\n","      <td>Lobbyist</td>\n","      <td>60156.97</td>\n","      <td>4953.27</td>\n","      <td>Success</td>\n","      <td>Yes</td>\n","      <td>False</td>\n","      <td>427</td>\n","      <td>Community war actually prove get.</td>\n","    </tr>\n","    <tr>\n","      <th>50099</th>\n","      <td>ab3afc94-68fa-4ff3-908f-c3c3d3adde2c</td>\n","      <td>ZOSQ21433952753674</td>\n","      <td>2021-02-14 13:08:50</td>\n","      <td>4307.44</td>\n","      <td>Spencer-Pruitt</td>\n","      <td>Debit</td>\n","      <td>Grocery</td>\n","      <td>San Jose</td>\n","      <td>USA</td>\n","      <td>Credit Card</td>\n","      <td>35</td>\n","      <td>Others</td>\n","      <td>Geophysicist/field seismologist</td>\n","      <td>76870.23</td>\n","      <td>19545.84</td>\n","      <td>Pending</td>\n","      <td>No</td>\n","      <td>False</td>\n","      <td>445</td>\n","      <td>Bar should without want else.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>50100 rows Ã— 20 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07cfb1d2-e3d0-4a81-bd39-105839c15d65')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-07cfb1d2-e3d0-4a81-bd39-105839c15d65 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-07cfb1d2-e3d0-4a81-bd39-105839c15d65');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_bb0d54aa-3c18-4148-ad1c-409b8600c31d\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_bb0d54aa-3c18-4148-ad1c-409b8600c31d button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 50100,\n  \"fields\": [\n    {\n      \"column\": \"Transaction_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50100,\n        \"samples\": [\n          \"1eca753d-73e8-4810-8b4b-16123ad1c35d\",\n          \"8c4a0c19-58b6-46ec-8aa1-fafacc9cf9e5\",\n          \"622d23d3-ca1b-40c5-ae6e-c05049b94cc8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Account_Number\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5389,\n        \"samples\": [\n          \"ELHU08437699296444\",\n          \"BELY89632174357483\",\n          \"EQRV73381745498562\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transaction_Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-01-01 00:31:48\",\n        \"max\": \"2025-01-20 12:21:18\",\n        \"num_unique_values\": 49991,\n        \"samples\": [\n          \"2022-02-27 13:16:52\",\n          \"2022-07-17 00:52:06\",\n          \"2020-01-22 13:51:31\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transaction_Amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6813.107323897727,\n        \"min\": 5.46,\n        \"max\": 619750.4328879906,\n        \"num_unique_values\": 5394,\n        \"samples\": [\n          2191.18,\n          767.43,\n          4726.21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Merchant_Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4880,\n        \"samples\": [\n          \"Miller-Thornton\",\n          \"Cruz and Sons\",\n          \"Gentry Ltd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transaction_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Credit\",\n          \"Debit\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"Fitness\",\n          \"Travel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Los Angeles\",\n          \"new york\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"USA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Payment_Method\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Cash  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Customer_Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 18,\n        \"max\": 70,\n        \"num_unique_values\": 53,\n        \"samples\": [\n          57\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Customer_Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Others\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Customer_Occupation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 639,\n        \"samples\": [\n          \"Location manager\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Customer_Income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37473.46211112199,\n        \"min\": 20028.94,\n        \"max\": 149970.5,\n        \"num_unique_values\": 5388,\n        \"samples\": [\n          76729.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Account_Balance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5716.31283616081,\n        \"min\": 101.72,\n        \"max\": 19993.04,\n        \"num_unique_values\": 5379,\n        \"samples\": [\n          13336.78\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transaction_Status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Failed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fraud_Flag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Discount_Applied\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Loyalty_Points_Earned\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 145,\n        \"min\": 0,\n        \"max\": 500,\n        \"num_unique_values\": 501,\n        \"samples\": [\n          249\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transaction_Description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5389,\n        \"samples\": [\n          \"Community away simple through clear politics red.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","# ğŸ¦ PROYECTO: GENERACIÃ“N DE DATASET BANCARIO (DISTRIBUCIÃ“N EQUILIBRADA)\n","# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","\n","import kagglehub\n","import pandas as pd\n","import numpy as np\n","import uuid\n","import os\n","from datetime import datetime\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"âœ… Entorno configurado.\\n\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# PASO 2: EXTRACCIÃ“N Y LIMPIEZA ESTRUCTURAL\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"ğŸ“¥ Obteniendo esquema de datos...\")\n","try:\n","    path = kagglehub.dataset_download(\"pradeepkumar2424/usa-banking-transactions-dataset-2023-2024\")\n","    csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n","\n","    if not csv_files: raise FileNotFoundError(\"CSV no encontrado.\")\n","\n","    # Cargamos solo para obtener estructura y valores categÃ³ricos vÃ¡lidos\n","    df_origen = pd.read_csv(os.path.join(path, csv_files[0]))\n","\n","    # Creamos una plantilla limpia (sin filas)\n","    print(f\"âœ… Esquema detectado: {df_origen.columns.tolist()}\")\n","\n","except Exception as e:\n","    print(f\"âŒ Error crÃ­tico: {e}\")\n","    raise\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# PASO 3: ALGORITMO DE GENERACIÃ“N CONTROLADA (MAX 15K/AÃ‘O)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","OBJETIVO_FILAS = 50000\n","print(f\"ğŸ”„ Generando {OBJETIVO_FILAS:,} transacciones con distribuciÃ³n acotada...\")\n","\n","# Usamos muestreo con reemplazo del original para mantener coherencia en datos categÃ³ricos\n","# pero reiniciaremos las fechas y IDs totalmente.\n","df_generado = df_origen.sample(n=OBJETIVO_FILAS, replace=True).copy()\n","\n","def generate_balanced_dates(n):\n","    \"\"\"\n","    Distribuye fechas respetando un lÃ­mite de ~15k por aÃ±o.\n","    PatrÃ³n: Alto -> Bajo -> Max(15k) -> Bajo -> Alto\n","    \"\"\"\n","    # DEFINICIÃ“N DE PESOS (Suma = 1.0)\n","    # 0.30 * 50,000 = 15,000 (Cumple la restricciÃ³n exacta del pico)\n","    scenario_probs = {\n","        2020: 0.20,  # ~10,000\n","        2021: 0.15,  # ~7,500  (CaÃ­da respecto a 2020)\n","        2022: 0.30,  # ~15,000 (PICO MÃXIMO)\n","        2023: 0.15,  # ~7,500  (Valle)\n","        2024: 0.20   # ~10,000 (RecuperaciÃ³n)\n","    }\n","\n","    years = list(scenario_probs.keys())\n","    probs = list(scenario_probs.values())\n","\n","    # 1. AsignaciÃ³n vectorizada de aÃ±os\n","    chosen_years = np.random.choice(years, size=n, p=probs)\n","\n","    # 2. GeneraciÃ³n de fechas intra-anuales\n","    dates = []\n","    counts = pd.Series(chosen_years).value_counts()\n","\n","    for year, count in counts.items():\n","        # Timestamp de inicio y fin de aÃ±o\n","        start = pd.Timestamp(f\"{year}-01-01\").value\n","        end = pd.Timestamp(f\"{year}-12-31\").value\n","\n","        # GeneraciÃ³n uniforme dentro del aÃ±o\n","        random_ts = np.random.randint(start, end, count)\n","        dates.extend(pd.to_datetime(random_ts))\n","\n","    np.random.shuffle(dates)\n","    return dates\n","\n","# Aplicar generador\n","fechas_finales = generate_balanced_dates(OBJETIVO_FILAS)\n","df_generado['Transaction_Date'] = fechas_finales\n","\n","# 3.1 Integridad Referencial (Nuevos IDs)\n","print(\"   â€¢ Asignando UUIDs v4 Ãºnicos...\")\n","df_generado['Transaction_ID'] = [str(uuid.uuid4()) for _ in range(OBJETIVO_FILAS)]\n","\n","# 3.2 VariaciÃ³n de Cuentas (Noise Injection)\n","if 'Account_Number' in df_generado.columns:\n","    df_generado['Account_Number'] = df_generado['Account_Number'].apply(\n","        lambda x: str(int(str(x)) + np.random.randint(-500, 500)) if str(x).isdigit() else x\n","    )\n","\n","# Ordenamiento temporal final\n","df_final = df_generado.sort_values('Transaction_Date').reset_index(drop=True)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# PASO 4: ENSUCIAMIENTO DE DATOS (KDD PREPARATION)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"ğŸ§¹ Inyectando anomalÃ­as y ruido...\")\n","\n","df = df_final.copy()\n","\n","# Nulos (5%)\n","columnas_sucias = ['Customer_Occupation', 'Transaction_Description', 'City']\n","for col in columnas_sucias:\n","    if col in df.columns:\n","        df.loc[df.sample(frac=0.05).index, col] = np.nan\n","\n","# Inconsistencias de Texto (7%)\n","if 'City' in df.columns:\n","    idx = df.sample(frac=0.07).index\n","    df.loc[idx, 'City'] = df.loc[idx, 'City'].str.lower()\n","\n","# Outliers (Montos)\n","if 'Transaction_Amount' in df.columns:\n","    # 20 transacciones con montos inflados\n","    idx_out = df.sample(n=20).index\n","    df.loc[idx_out, 'Transaction_Amount'] *= np.random.uniform(10, 50, 20)\n","\n","print(f\"âœ… Dataset finalizado: {df.shape}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# VALIDACIÃ“N DE REQUISITOS (PROOF OF DISTRIBUTION)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"\\nğŸ“Š REPORTE DE DISTRIBUCIÃ“N ANUAL:\")\n","print(\"=\"*60)\n","conteo = df['Transaction_Date'].dt.year.value_counts().sort_index()\n","print(conteo)\n","print(\"=\"*60)\n","print(f\"TOTAL: {conteo.sum():,}\")\n","\n","# Assertions para garantizar calidad antes de subir\n","pico = conteo.max()\n","anio_pico = conteo.idxmax()\n","\n","try:\n","    assert pico <= 15500, f\"âš ï¸ ALERTA: El pico ({pico}) excede el lÃ­mite de tolerancia (15k).\"\n","    assert anio_pico == 2022, f\"âš ï¸ ALERTA: El aÃ±o pico es {anio_pico}, deberÃ­a ser 2022.\"\n","    assert conteo[2021] < conteo[2020], \"âš ï¸ ALERTA: No hubo bajada en 2021.\"\n","    print(\"\\nâœ… VALIDACIÃ“N EXITOSA: DistribuciÃ³n correcta y bajo el lÃ­mite de 15k.\")\n","except AssertionError as e:\n","    print(f\"\\nâŒ ERROR DE VALIDACIÃ“N: {e}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# PASO 6: CARGA A FIREBASE (MODO SILENCIOSO / COMENTADO)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\"\"\"\n","print(\"\\nâ˜ï¸  Preparando subida a Firebase...\")\n","\n","# SerializaciÃ³n\n","df_subida = df.copy()\n","df_subida['Transaction_Date'] = df_subida['Transaction_Date'].astype(str)\n","df_subida = df_subida.fillna(\"N/A\")\n","data_firebase = df_subida.set_index('Transaction_ID').to_dict(orient='index')\n","\n","BASE_URL = \"https://bifrost-e5592-default-rtdb.firebaseio.com/\"\n","NODO = \"transacciones_bancarias\"\n","TAMAÃ‘O_LOTE = 1000\n","\n","# LÃ³gica de subida (request.patch) omitida intencionalmente para revisiÃ³n de datos.\n","# Descomentar el bucle de subida cuando la distribuciÃ³n de datos sea aprobada.\n","\"\"\"\n","\n","print(\"\\nğŸš€ LISTO. Revisa los conteos arriba. Si te gusta la distribuciÃ³n, descomenta la carga.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z3vbfLuepuwq","executionInfo":{"status":"ok","timestamp":1769739404386,"user_tz":300,"elapsed":2178,"user":{"displayName":"Johan Caizaguano","userId":"03823090711317079059"}},"outputId":"e1cd1e0f-7037-4ba4-d60f-e9ef6978dde9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Entorno configurado.\n","\n","ğŸ“¥ Obteniendo esquema de datos...\n","Using Colab cache for faster access to the 'usa-banking-transactions-dataset-2023-2024' dataset.\n","âœ… Esquema detectado: ['Transaction_ID', 'Account_Number', 'Transaction_Date', 'Transaction_Amount', 'Merchant_Name', 'Transaction_Type', 'Category', 'City', 'Country', 'Payment_Method', 'Customer_Age', 'Customer_Gender', 'Customer_Occupation', 'Customer_Income', 'Account_Balance', 'Transaction_Status', 'Fraud_Flag', 'Discount_Applied', 'Loyalty_Points_Earned', 'Transaction_Description']\n","ğŸ”„ Generando 50,000 transacciones con distribuciÃ³n acotada...\n","   â€¢ Asignando UUIDs v4 Ãºnicos...\n","ğŸ§¹ Inyectando anomalÃ­as y ruido...\n","âœ… Dataset finalizado: (50000, 20)\n","\n","ğŸ“Š REPORTE DE DISTRIBUCIÃ“N ANUAL:\n","============================================================\n","Transaction_Date\n","2020     9913\n","2021     7583\n","2022    15067\n","2023     7354\n","2024    10083\n","Name: count, dtype: int64\n","============================================================\n","TOTAL: 50,000\n","\n","âœ… VALIDACIÃ“N EXITOSA: DistribuciÃ³n correcta y bajo el lÃ­mite de 15k.\n","\n","ğŸš€ LISTO. Revisa los conteos arriba. Si te gusta la distribuciÃ³n, descomenta la carga.\n"]}]},{"cell_type":"code","source":["# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","# ğŸ¦ PROYECTO: GENERACIÃ“N DE DATASET BANCARIO (CRECIMIENTO REALISTA)\n","# Autor: Tu nombre\n","# Objetivo: Simular un banco en expansiÃ³n (Tendencia positiva para predicciÃ³n)\n","# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","\n","import kagglehub\n","import pandas as pd\n","import numpy as np\n","import uuid\n","import os\n","import requests\n","import json\n","from datetime import datetime\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"âœ… Entorno configurado.\\n\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# PASO 2: EXTRACCIÃ“N Y LIMPIEZA ESTRUCTURAL\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"ğŸ“¥ Obteniendo esquema de datos...\")\n","try:\n","    path = kagglehub.dataset_download(\"pradeepkumar2424/usa-banking-transactions-dataset-2023-2024\")\n","    csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n","\n","    if not csv_files: raise FileNotFoundError(\"CSV no encontrado.\")\n","\n","    # Cargamos solo para obtener estructura\n","    df_origen = pd.read_csv(os.path.join(path, csv_files[0]))\n","    print(f\"âœ… Esquema detectado: {df_origen.columns.tolist()}\")\n","\n","except Exception as e:\n","    print(f\"âŒ Error crÃ­tico: {e}\")\n","    raise\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# PASO 3: ALGORITMO DE GENERACIÃ“N (CRECIMIENTO SOSTENIDO)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","OBJETIVO_FILAS = 50000\n","print(f\"ğŸ”„ Generando {OBJETIVO_FILAS:,} transacciones con TENDENCIA POSITIVA...\")\n","\n","# Muestreo base\n","df_generado = df_origen.sample(n=OBJETIVO_FILAS, replace=True).copy()\n","\n","def generate_growth_dates(n):\n","    \"\"\"\n","    Distribuye fechas simulan un NEGOCIO EN CRECIMIENTO.\n","    Cada aÃ±o tiene mÃ¡s transacciones que el anterior.\n","    \"\"\"\n","    # ğŸ“Š ESTRATEGIA: Crecimiento Lineal\n","    # La suma de probabilidades debe ser 1.0\n","    scenario_probs = {\n","        2020: 0.10,  # 10% (Inicio: ~5,000 tx)\n","        2021: 0.15,  # 15% (Crecimiento)\n","        2022: 0.20,  # 20% (ConsolidaciÃ³n)\n","        2023: 0.25,  # 25% (ExpansiÃ³n)\n","        2024: 0.30   # 30% (Ã‰xito actual: ~15,000 tx)\n","    }\n","\n","    years = list(scenario_probs.keys())\n","    probs = list(scenario_probs.values())\n","\n","    # 1. AsignaciÃ³n de aÃ±os basada en probabilidad de crecimiento\n","    chosen_years = np.random.choice(years, size=n, p=probs)\n","\n","    # 2. GeneraciÃ³n de fechas detalladas\n","    dates = []\n","    counts = pd.Series(chosen_years).value_counts()\n","\n","    for year, count in counts.items():\n","        start = pd.Timestamp(f\"{year}-01-01\").value\n","        end = pd.Timestamp(f\"{year}-12-31\").value\n","        # Uniforme dentro del aÃ±o\n","        random_ts = np.random.randint(start, end, count)\n","        dates.extend(pd.to_datetime(random_ts))\n","\n","    np.random.shuffle(dates)\n","    return dates\n","\n","# Aplicar generador\n","fechas_finales = generate_growth_dates(OBJETIVO_FILAS)\n","df_generado['Transaction_Date'] = fechas_finales\n","\n","# 3.1 Integridad Referencial\n","print(\"   â€¢ Asignando UUIDs v4 Ãºnicos...\")\n","df_generado['Transaction_ID'] = [str(uuid.uuid4()) for _ in range(OBJETIVO_FILAS)]\n","\n","# 3.2 VariaciÃ³n de Cuentas (Ruido leve)\n","if 'Account_Number' in df_generado.columns:\n","    df_generado['Account_Number'] = df_generado['Account_Number'].apply(\n","        lambda x: str(int(str(x)) + np.random.randint(-500, 500)) if str(x).isdigit() else x\n","    )\n","\n","# Ordenar cronolÃ³gicamente (ayuda a la visualizaciÃ³n)\n","df_final = df_generado.sort_values('Transaction_Date').reset_index(drop=True)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# PASO 4: ENSUCIAMIENTO DE DATOS (PREPARACIÃ“N KDD)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"ğŸ§¹ Inyectando anomalÃ­as y ruido (Data Dirtying)...\")\n","\n","df = df_final.copy()\n","\n","# Nulos (5%)\n","columnas_sucias = ['Customer_Occupation', 'Transaction_Description', 'City']\n","for col in columnas_sucias:\n","    if col in df.columns:\n","        df.loc[df.sample(frac=0.05).index, col] = np.nan\n","\n","# Inconsistencias de Texto (7%) - \"new york\" vs \"New York\"\n","if 'City' in df.columns:\n","    idx = df.sample(frac=0.07).index\n","    df.loc[idx, 'City'] = df.loc[idx, 'City'].str.lower()\n","\n","# Outliers (Montos extremos)\n","if 'Transaction_Amount' in df.columns:\n","    # 25 transacciones con montos multiplicados por 10x-50x\n","    idx_out = df.sample(n=25).index\n","    df.loc[idx_out, 'Transaction_Amount'] *= np.random.uniform(10, 50, 25)\n","\n","print(f\"âœ… Dataset finalizado: {df.shape}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# VALIDACIÃ“N DE REQUISITOS (PROOF OF GROWTH)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"\\nğŸ“Š REPORTE DE DISTRIBUCIÃ“N ANUAL (DeberÃ­a ser creciente):\")\n","print(\"=\"*60)\n","conteo = df['Transaction_Date'].dt.year.value_counts().sort_index()\n","print(conteo)\n","print(\"=\"*60)\n","\n","# Validaciones actualizadas para Crecimiento\n","try:\n","    # Verificar que 2024 tiene mÃ¡s trÃ¡fico que 2020 (Tendencia Positiva)\n","    assert conteo[2024] > conteo[2020], \"âš ï¸ ALERTA: No hay crecimiento a largo plazo.\"\n","\n","    # Verificar que el Ãºltimo aÃ±o es el mÃ¡s fuerte (o casi)\n","    assert conteo.idxmax() == 2024, f\"âš ï¸ ALERTA: El aÃ±o pico no es el actual ({conteo.idxmax()}).\"\n","\n","    print(\"\\nâœ… VALIDACIÃ“N EXITOSA: El dataset muestra un crecimiento saludable.\")\n","    print(\"   (Ideal para predecir tendencias futuras)\")\n","except AssertionError as e:\n","    print(f\"\\nâŒ ERROR DE VALIDACIÃ“N: {e}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# PASO 6: CARGA A FIREBASE\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","# âš ï¸ SI ESTÃS LISTO, DESCOMENTA ESTO PARA SUBIR LOS DATOS âš ï¸\n","\n","\"\"\"\n","print(\"\\nâ˜ï¸  Subiendo a Firebase Realtime Database...\")\n","\n","# Preparar datos\n","df_subida = df.copy()\n","df_subida['Transaction_Date'] = df_subida['Transaction_Date'].astype(str)\n","df_subida = df_subida.fillna(\"N/A\")\n","data_firebase = df_subida.set_index('Transaction_ID').to_dict(orient='index')\n","\n","BASE_URL = \"https://bifrost-e5592-default-rtdb.firebaseio.com/\" # TU URL AQUÃ\n","NODO = \"transacciones_bancarias\"\n","TAMAÃ‘O_LOTE = 1000\n","\n","def subir_lote(nodo, datos_lote):\n","    url = f\"{BASE_URL}{nodo}.json\"\n","    try:\n","        response = requests.patch(url, data=json.dumps(datos_lote), timeout=30)\n","        return response.status_code == 200\n","    except:\n","        return False\n","\n","# Dividir y subir\n","transaction_ids = list(data_firebase.keys())\n","total_lotes = (len(transaction_ids) + TAMAÃ‘O_LOTE - 1) // TAMAÃ‘O_LOTE\n","\n","exitosos = 0\n","for i in tqdm(range(total_lotes), desc=\"Subiendo lotes\"):\n","    inicio = i * TAMAÃ‘O_LOTE\n","    fin = min((i + 1) * TAMAÃ‘O_LOTE, len(transaction_ids))\n","    ids_lote = transaction_ids[inicio:fin]\n","    datos_lote = {id_: data_firebase[id_] for id_ in ids_lote}\n","\n","    if subir_lote(NODO, datos_lote):\n","        exitosos += len(datos_lote)\n","\n","print(f\"\\nâœ… SUBIDA COMPLETADA: {exitosos:,} registros subidos.\")\n","\"\"\"\n","\n","print(\"\\nğŸš€ LISTO. Revisa que los aÃ±os 2020->2024 vayan subiendo en cantidad.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adUJLkJifAVT","executionInfo":{"status":"ok","timestamp":1769786330495,"user_tz":300,"elapsed":10402,"user":{"displayName":"Juan Carlos Tapia","userId":"12472010642874200463"}},"outputId":"987ae4a7-b5e8-4c86-e6d6-cd31bbded3ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Entorno configurado.\n","\n","ğŸ“¥ Obteniendo esquema de datos...\n","Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n","Downloading from https://www.kaggle.com/api/v1/datasets/download/pradeepkumar2424/usa-banking-transactions-dataset-2023-2024?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 580k/580k [00:00<00:00, 32.0MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["âœ… Esquema detectado: ['Transaction_ID', 'Account_Number', 'Transaction_Date', 'Transaction_Amount', 'Merchant_Name', 'Transaction_Type', 'Category', 'City', 'Country', 'Payment_Method', 'Customer_Age', 'Customer_Gender', 'Customer_Occupation', 'Customer_Income', 'Account_Balance', 'Transaction_Status', 'Fraud_Flag', 'Discount_Applied', 'Loyalty_Points_Earned', 'Transaction_Description']\n","ğŸ”„ Generando 50,000 transacciones con TENDENCIA POSITIVA...\n","   â€¢ Asignando UUIDs v4 Ãºnicos...\n","ğŸ§¹ Inyectando anomalÃ­as y ruido (Data Dirtying)...\n","âœ… Dataset finalizado: (50000, 20)\n","\n","ğŸ“Š REPORTE DE DISTRIBUCIÃ“N ANUAL (DeberÃ­a ser creciente):\n","============================================================\n","Transaction_Date\n","2020     4906\n","2021     7786\n","2022    10021\n","2023    12464\n","2024    14823\n","Name: count, dtype: int64\n","============================================================\n","\n","âœ… VALIDACIÃ“N EXITOSA: El dataset muestra un crecimiento saludable.\n","   (Ideal para predecir tendencias futuras)\n","\n","ğŸš€ LISTO. Revisa que los aÃ±os 2020->2024 vayan subiendo en cantidad.\n"]}]},{"cell_type":"code","source":["# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","# ğŸ¦ GENERADOR DEFINITIVO -> DATASET_BANCARIO_KDD_50K.CSV EN DRIVE\n","# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","\n","import kagglehub\n","import pandas as pd\n","import numpy as np\n","import uuid\n","import os\n","import shutil\n","from google.colab import drive\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"ğŸš€ INICIANDO PROCESO COMPLETO...\")\n","\n","# 1. DESCARGAR BASE DE KAGGLE\n","print(\"ğŸ“¥ Descargando base...\")\n","path = kagglehub.dataset_download(\"pradeepkumar2424/usa-banking-transactions-dataset-2023-2024\")\n","csv_file = [f for f in os.listdir(path) if f.endswith('.csv')][0]\n","df_origen = pd.read_csv(os.path.join(path, csv_file))\n","\n","# 2. GENERAR 50,000 FILAS CON CRECIMIENTO REALISTA (SIN ZIG-ZAG)\n","print(\"ğŸ”„ Generando 50,000 filas con tendencia positiva...\")\n","OBJETIVO = 50000\n","df_generado = df_origen.sample(n=OBJETIVO, replace=True).copy()\n","\n","# Probabilidades: 2020 (10%) -> 2024 (30%)\n","years = [2020, 2021, 2022, 2023, 2024]\n","probs = [0.10, 0.15, 0.20, 0.25, 0.30]\n","chosen_years = np.random.choice(years, size=OBJETIVO, p=probs)\n","\n","dates = []\n","for year, count in pd.Series(chosen_years).value_counts().items():\n","    start = pd.Timestamp(f\"{year}-01-01\").value\n","    end = pd.Timestamp(f\"{year}-12-31\").value\n","    dates.extend(pd.to_datetime(np.random.randint(start, end, count)))\n","\n","df_generado['Transaction_Date'] = np.random.permutation(dates)\n","df_generado['Transaction_ID'] = [str(uuid.uuid4()) for _ in range(OBJETIVO)]\n","\n","# 3. ENSUCIAR DATOS (Data Dirtying)\n","print(\"ğŸ§¹ Ensuciando datos (Nulos, Outliers, Texto)...\")\n","df = df_generado.sort_values('Transaction_Date').reset_index(drop=True)\n","# Nulos\n","for col in ['Customer_Occupation', 'Transaction_Description', 'City']:\n","    if col in df.columns: df.loc[df.sample(frac=0.05).index, col] = np.nan\n","# Outliers en Montos\n","if 'Transaction_Amount' in df.columns:\n","    idx = df.sample(n=25).index\n","    df.loc[idx, 'Transaction_Amount'] *= np.random.uniform(10, 50, 25)\n","\n","# 4. GUARDAR EN DRIVE\n","print(\"ğŸ’¾ Guardando archivo en Google Drive...\")\n","\n","# Montamos el Drive\n","drive.mount('/content/drive')\n","\n","# Definimos rutas\n","nombre_archivo = \"dataset_bancario_kdd_50k.csv\"\n","ruta_destino = f\"/content/drive/MyDrive/SEXTO SEMESTRE/bifrost/{nombre_archivo}\"\n","carpeta_destino = os.path.dirname(ruta_destino)\n","\n","# Crear carpeta si no existe y guardar\n","if not os.path.exists(carpeta_destino):\n","    os.makedirs(carpeta_destino)\n","\n","df.to_csv(ruta_destino, index=False)\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"âœ… Â¡LISTO! ARCHIVO CREADO EXITOSAMENTE\")\n","print(\"=\"*60)\n","print(f\"ğŸ“‚ UbicaciÃ³n: {ruta_destino}\")\n","print(f\"ğŸ“Š Filas: {len(df):,}\")\n","print(\"ğŸ“ˆ DistribuciÃ³n generada (Crecimiento):\")\n","print(df['Transaction_Date'].dt.year.value_counts().sort_index())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UyOrgH_MgKN_","executionInfo":{"status":"ok","timestamp":1769786645483,"user_tz":300,"elapsed":28892,"user":{"displayName":"Juan Carlos Tapia","userId":"12472010642874200463"}},"outputId":"1be87405-73d0-4c63-cf5c-52b7ee614603"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸš€ INICIANDO PROCESO COMPLETO...\n","ğŸ“¥ Descargando base...\n","Using Colab cache for faster access to the 'usa-banking-transactions-dataset-2023-2024' dataset.\n","ğŸ”„ Generando 50,000 filas con tendencia positiva...\n","ğŸ§¹ Ensuciando datos (Nulos, Outliers, Texto)...\n","ğŸ’¾ Guardando archivo en Google Drive...\n","Mounted at /content/drive\n","\n","============================================================\n","âœ… Â¡LISTO! ARCHIVO CREADO EXITOSAMENTE\n","============================================================\n","ğŸ“‚ UbicaciÃ³n: /content/drive/MyDrive/SEXTO SEMESTRE/bifrost/dataset_bancario_kdd_50k.csv\n","ğŸ“Š Filas: 50,000\n","ğŸ“ˆ DistribuciÃ³n generada (Crecimiento):\n","Transaction_Date\n","2020     5051\n","2021     7492\n","2022     9850\n","2023    12627\n","2024    14980\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","# ğŸ•’ GENERADOR DE REPORTES MENSUALES FUTUROS (2023-2025)\n","# Objetivo: Crear 36 archivos CSV para simular la llegada de datos mes a mes\n","# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","\n","import pandas as pd\n","import numpy as np\n","import uuid\n","import os\n","import calendar\n","from google.colab import drive\n","\n","print(\"ğŸš€ INICIANDO GENERADOR DE REPORTES MENSUALES...\")\n","\n","# 1. CONECTAR DRIVE\n","drive.mount('/content/drive')\n","\n","# 2. CONFIGURACIÃ“N DE RUTAS\n","base_path = \"/content/drive/MyDrive/SEXTO SEMESTRE/bifrost\"\n","archivo_origen = os.path.join(base_path, \"dataset_bancario_kdd_50k.csv\")\n","carpeta_reportes = os.path.join(base_path, \"reportes\")\n","\n","# Crear carpeta de reportes si no existe\n","if not os.path.exists(carpeta_reportes):\n","    os.makedirs(carpeta_reportes)\n","    print(f\"ğŸ“‚ Carpeta creada: {carpeta_reportes}\")\n","else:\n","    print(f\"ğŸ“‚ Carpeta detectada: {carpeta_reportes}\")\n","\n","# 3. LEER DATASET BASE (Para usarlo como plantilla)\n","if os.path.exists(archivo_origen):\n","    print(\"ğŸ“– Leyendo dataset base para copiar estructura...\")\n","    df_base = pd.read_csv(archivo_origen)\n","else:\n","    raise FileNotFoundError(\"âŒ No se encuentra el archivo 'dataset_bancario_kdd_50k.csv'. Ejecuta el paso anterior primero.\")\n","\n","# 4. GENERACIÃ“N DE LOS 36 ARCHIVOS (2023, 2024, 2025)\n","anios_futuros = [2023, 2024, 2025]\n","total_archivos = 0\n","\n","print(\"\\nâš™ï¸ Generando archivos mensuales (SimulaciÃ³n de Crecimiento)...\")\n","\n","for year in anios_futuros:\n","    for month in range(1, 13): # Meses 1 al 12\n","\n","        # A. DEFINIR VOLUMEN (Simulamos crecimiento anual)\n","        # 2023: ~800 txs/mes | 2024: ~1000 txs/mes | 2025: ~1200 txs/mes\n","        base_volumen = 800 + ((year - 2023) * 200)\n","        n_filas = np.random.randint(base_volumen, base_volumen + 150)\n","\n","        # B. TOMAR MUESTRA ALEATORIA (Bootstrapping)\n","        df_mes = df_base.sample(n=n_filas, replace=True).copy()\n","\n","        # C. GENERAR FECHAS CORRECTAS PARA ESE MES\n","        ultimo_dia = calendar.monthrange(year, month)[1]\n","        dias = np.random.randint(1, ultimo_dia + 1, n_filas)\n","        horas = np.random.randint(0, 24, n_filas)\n","        minutos = np.random.randint(0, 60, n_filas)\n","        seconds = np.random.randint(0, 60, n_filas)\n","\n","        # Construir columna de fecha\n","        fechas = pd.to_datetime({\n","            'year': year, 'month': month, 'day': dias,\n","            'hour': horas, 'minute': minutos, 'second': seconds\n","        })\n","\n","        df_mes['Transaction_Date'] = fechas.sort_values().values\n","\n","        # D. GENERAR NUEVOS IDs ÃšNICOS (Para no repetir los del entrenamiento)\n","        df_mes['Transaction_ID'] = [str(uuid.uuid4()) for _ in range(n_filas)]\n","\n","        # E. LEVE INFLACIÃ“N EN MONTOS (Opcional: Hace mÃ¡s real la predicciÃ³n)\n","        # Aumentamos un 3% el monto por cada aÃ±o que pasa\n","        factor_inflacion = 1 + (0.03 * (year - 2022))\n","        if 'Transaction_Amount' in df_mes.columns:\n","            df_mes['Transaction_Amount'] = df_mes['Transaction_Amount'] * factor_inflacion\n","            df_mes['Transaction_Amount'] = df_mes['Transaction_Amount'].round(2)\n","\n","        # F. GUARDAR CSV INDIVIDUAL\n","        nombre_reporte = f\"Reporte_{year}_{month:02d}.csv\" # Ej: Reporte_2023_01.csv\n","        ruta_guardado = os.path.join(carpeta_reportes, nombre_reporte)\n","\n","        # Seleccionamos solo las columnas originales para mantener limpieza\n","        cols = df_base.columns\n","        df_mes[cols].to_csv(ruta_guardado, index=False)\n","\n","        total_archivos += 1\n","        # Feedback visual cada 6 meses para no saturar consola\n","        if month % 6 == 0:\n","            print(f\"   âœ… Generado: {nombre_reporte} ({n_filas} filas)\")\n","\n","print(\"\\n\" + \"=\"*60)\n","print(f\"ğŸ‰ Â¡MISION CUMPLIDA! SE GENERARON {total_archivos} ARCHIVOS CSV.\")\n","print(\"=\"*60)\n","print(f\"ğŸ“‚ UbicaciÃ³n: {carpeta_reportes}\")\n","print(\"ğŸ‘‰ Ahora puedes usar el botÃ³n 'Subir Reporte Real' en tu web y seleccionar cualquiera de estos archivos.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QEY2fgbPCfCC","executionInfo":{"status":"ok","timestamp":1769980278968,"user_tz":300,"elapsed":107426,"user":{"displayName":"Juan Carlos Tapia","userId":"12472010642874200463"}},"outputId":"83551fb2-2300-47c3-f4bc-9755f49f8eeb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸš€ INICIANDO GENERADOR DE REPORTES MENSUALES...\n","Mounted at /content/drive\n","ğŸ“‚ Carpeta creada: /content/drive/MyDrive/SEXTO SEMESTRE/bifrost/reportes\n","ğŸ“– Leyendo dataset base para copiar estructura...\n","\n","âš™ï¸ Generando archivos mensuales (SimulaciÃ³n de Crecimiento)...\n","   âœ… Generado: Reporte_2023_06.csv (881 filas)\n","   âœ… Generado: Reporte_2023_12.csv (924 filas)\n","   âœ… Generado: Reporte_2024_06.csv (1077 filas)\n","   âœ… Generado: Reporte_2024_12.csv (1034 filas)\n","   âœ… Generado: Reporte_2025_06.csv (1238 filas)\n","   âœ… Generado: Reporte_2025_12.csv (1250 filas)\n","\n","============================================================\n","ğŸ‰ Â¡MISION CUMPLIDA! SE GENERARON 36 ARCHIVOS CSV.\n","============================================================\n","ğŸ“‚ UbicaciÃ³n: /content/drive/MyDrive/SEXTO SEMESTRE/bifrost/reportes\n","ğŸ‘‰ Ahora puedes usar el botÃ³n 'Subir Reporte Real' en tu web y seleccionar cualquiera de estos archivos.\n"]}]}]}